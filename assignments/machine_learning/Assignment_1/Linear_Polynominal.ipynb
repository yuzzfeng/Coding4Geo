{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQywOnqTOSFj",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6972ba3a68f625c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Principles of Spatial Date Mining and Machine WS2022/2023 \n",
    "# Lectuer team: Martin Werner, Hao Li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-Am0H9VOSFm",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-23338df6ac0e8032",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Regression Excercise Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wg_Nvg1tOSFn",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f9b3b287daf4d794",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this exercise, we will try to implement linear regression and polynomial regression with the Boston housing price dataset, which we have used as an example during the lecutre. \n",
    "\n",
    "First, we would load the datasets together, do some basic data exploration, and split the entire datasets into train and test. \n",
    "\n",
    "Then, there are mainly two tasks for you in this excercise:\n",
    "\n",
    "- Build the linear regression model between 'RM' (average Number of rooms per person) and 'MEDV' (housing prices in 1000s US dollars), and calculate the mean_squared_error in the test dataset.\n",
    "    \n",
    "- Build the polynomial regression model between 'LSTAT' (percentage of lower status of the population) and 'MEDV' using different degrees of polynominal function (i.e., x^2, x^3 etc), and calculate the mean_squared_error in the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqrlbnLBOSFn",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-24bf002a796973c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Example Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3e555b5e2f7d25c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting scikit-learn==1.1.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/43/bc/7130ffd49a1cf72659c61eb94d8f037bc5502c94866f407c0219d929e758/scikit_learn-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.4/30.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /home/instructor/.local/lib/python3.10/site-packages (from scikit-learn==1.1.1) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/instructor/.local/lib/python3.10/site-packages (from scikit-learn==1.1.1) (1.24.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/instructor/.local/lib/python3.10/site-packages (from scikit-learn==1.1.1) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/instructor/.local/lib/python3.10/site-packages (from scikit-learn==1.1.1) (3.1.0)\n",
      "Installing collected packages: scikit-learn\n",
      "Successfully installed scikit-learn-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.1.1 -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "UUGGApjJOSFo",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-51a19b3f2ffea0f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "\n",
    "#imports from sklearn library\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "#Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#To plot the graph embedded in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74W6eJ3gOSFp",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-657a0127743c06ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ytffoeFjOSFp",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3262a38bffb2b20b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# loading the Bouston dataset direclty from sklearn\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m boston \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_boston\u001b[49m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/datasets/__init__.py:156\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_boston\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    106\u001b[0m     msg \u001b[38;5;241m=\u001b[39m textwrap\u001b[38;5;241m.\u001b[39mdedent(\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m        `load_boston` has been removed from scikit-learn since version 1.2.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     )\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[name]\n",
      "\u001b[0;31mImportError\u001b[0m: \n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n"
     ]
    }
   ],
   "source": [
    "# loading the Bouston dataset direclty from sklearn\n",
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OmwSZ9YOSFq",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d9ec3e3f055c8dd3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Now let us print the attributes,, and check which attributes are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "t-qP_TomOSFq",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c90550a8b4541978",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "ee8187f1-99c3-41a0-a337-f7da50189b39",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(boston))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mboston\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m())\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(boston\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# Print the python data tpye and size of boston dataset together with the feature_names\n",
    "\n",
    "print(type(boston))\n",
    "print('\\n')\n",
    "print(boston.keys())\n",
    "print('\\n')\n",
    "print(boston.data.shape)\n",
    "print('\\n')\n",
    "print(boston.feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fiGftZMOSFr",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b7a53237f412cdf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## The features can be summarized as follows (https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfUUGND0OSFr",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-09b75a71db546a50",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "\n",
    "- CRIM: This is the per capita crime rate by town\n",
    "- ZN: This is the proportion of residential land zoned for lots larger than 25,000 sq.ft.\n",
    "- INDUS: This is the proportion of non-retail business acres per town.\n",
    "- CHAS: This is the Charles River dummy variable (this is equal to 1 if tract bounds river; 0 otherwise)\n",
    "- NOX: This is the nitric oxides concentration (parts per 10 million)\n",
    "- RM: This is the average number of rooms per dwelling\n",
    "- AGE: This is the proportion of owner-occupied units built prior to 1940\n",
    "- DIS: This is the weighted distances to five Boston employment centers\n",
    "- RAD: This is the index of accessibility to radial highways\n",
    "- TAX: This is the full-value property-tax rate per 10,000 dollars\n",
    "- PTRATIO: This is the pupil-teacher ratio by town\n",
    "- B: This is calculated as 1000(Bk — 0.63)², where Bk is the proportion of people of African American descent by town\n",
    "- LSTAT: This is the percentage lower status of the population\n",
    "- MEDV: This is the median value of owner-occupied homes in 1,000 dollars\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "IvaLPJHUOSFs",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ad929b0e1d02f9a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "875f39a4-bcbe-4446-c80b-a4962bbdc58a"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert boston data into pandas dataframe \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m boston_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mboston\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m, columns\u001b[38;5;241m=\u001b[39mboston\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[1;32m      4\u001b[0m boston_data\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "# Convert boston data into pandas dataframe \n",
    "\n",
    "boston_data = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "boston_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSQ50Bf5OSFs",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7768d9df80f6db79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "16f7a1d5-7a5a-4759-b107-e259a5b5f259"
   },
   "outputs": [],
   "source": [
    "# Append the price feature as a colunm from the boston\n",
    "boston_data['MEDV'] = boston.target\n",
    "print(boston_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "msMyc6KkOSFt",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-16f71ac2bf932776",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "eb644511-36d0-4cd9-ae6c-0d9dcdbbb3f4"
   },
   "outputs": [],
   "source": [
    "# scatter plot using'RM' and 'LSTAT' as x axis, and 'MEDV' as y axis\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "features = ['LSTAT', 'RM']\n",
    "target = boston_data['MEDV']\n",
    "\n",
    "for i, col in enumerate(features):\n",
    "    plt.subplot(1, len(features) , i+1)\n",
    "    x = boston_data[col]\n",
    "    y = target\n",
    "    plt.scatter(x, y, marker='x')\n",
    "    plt.title(col)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('MEDV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnx4UWgyOSFt",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fdd330ffcd59a900",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Now, it is your turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjGArH-kOSFt",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fead11bd3d1e0d83",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task No.1: fit a linear regression model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_gyrrUuOSFt",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7b878eb425efe8f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q1.1: define the split ratio between training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wcu1n-QYOSFu",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-36bf81b3cc459deb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "5a3d3b27-adb5-4f3a-d3e2-d2b181802629"
   },
   "outputs": [],
   "source": [
    "# split the boston hoursing dataset into training and validation\n",
    "\n",
    "# tips: try to remember the default ratio we disucssed in the lecture \n",
    "ratio = 0.2 # split ratio\n",
    "\n",
    "X = boston_data['RM'].values.reshape(-1,1)\n",
    "\n",
    "Y = boston_data['MEDV']\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = ratio, random_state=5)\n",
    "\n",
    "#print the size of train and train dataset\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-68aa8fe9670b6419",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "try: \n",
    "   assert x_train.shape == (404, 1)\n",
    "except: \n",
    "   print('Element shape of x_train is not correct. shape is not correct')\n",
    "\n",
    "try: \n",
    "   assert y_train.shape == (404,)\n",
    "except: \n",
    "   print('Element shape of y_train is not correct. shape is not correct')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnX06NGMOSFu",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8ad7c218d191cf24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q1.2: print the size of test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eHGgjZ7TOSFu",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f678d92904ab387b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "c524fd1f-6973-41f9-95fd-91e9bb9010c1"
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6386ce02461d45e3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "try: \n",
    "   assert x_test.shape == (102, 1)\n",
    "except: \n",
    "   print('Element shape of x_test is not correct. shape is not correct')\n",
    "\n",
    "try: \n",
    "   assert y_test.shape == (102,)\n",
    "except: \n",
    "   print('Element shape of y_test is not correct. shape is not correct')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yi4aNO-LOSFu",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-258e8acc69d2b203",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# initial a linear regression model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# fit a linear regression to linear features.\n",
    "# tips: for the LinearRegression.fit(x,y) function, herein x will be your input feature and y is the label\n",
    "lin_reg.fit(x_train, y_train)\n",
    "\n",
    "# calculate the y_hat from the trained model\n",
    "y_train_pred = lin_reg.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUijk5EDOSFu",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-913f70215153e0c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q1.3:  plot the fitted line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-azKmKlOSFv",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-775575b027be2af9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "f7ed9ebe-de25-4fdb-e356-f202a3ed4ed7"
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# plot the results\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(x_train, y_train, marker='x')\n",
    "\n",
    "# sort the values of x before line plot\n",
    "sort_axis = operator.itemgetter(0)\n",
    "sorted_zip = sorted(zip(x_train,y_train_pred), key=sort_axis)\n",
    "x_plot, y_polt_pred = zip(*sorted_zip)\n",
    "\n",
    "plt.plot(x_plot, y_polt_pred, color='red')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e59ed7ab8d73f8eb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "try: \n",
    "   assert len(x_train) == len(sorted_zip) == 404\n",
    "\n",
    "except:  \n",
    "   print(\"Incorrcet y_pred. Please check your prediction result again.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPKd8lcaOSFv",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d1671a46dd798493",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "f322b033-001e-4d31-ec9b-0bd53f995fc3"
   },
   "outputs": [],
   "source": [
    "# tips: calculate the y_hat for the validatiaon set in a similar way.\n",
    "y_test_predict = lin_reg.predict(x_test)\n",
    "\n",
    "# model evaluation for validatiaon set\n",
    "mse = mean_squared_error(y_test, y_test_predict)\n",
    "print(\"The model performance for validatiaon set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('MSE is {}'.format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhqD3td4OSFv",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-de494cb1d2b5a009",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task No.2: fit a polynomial regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIV5ObbuOSFv",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96acdb1dd93aacf1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# split the boston hoursing dataset into training and testing \n",
    "\n",
    "ratio = 0.2 # split ratio\n",
    "\n",
    "X = boston_data['LSTAT'].values.reshape(-1,1)\n",
    "\n",
    "Y = boston_data['MEDV']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXC8WqLuOSFv",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3a2e99dfa5d8e2c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q2.1: split the training data and the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ts3M__-9OSFw",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0a18567238b5e95f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# tips: similar as we did for linear feature\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4be4a6bead75bc24",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "try: \n",
    "   assert x_train.shape ==(404, 1) and y_train.shape ==(404,) and x_test.shape == (102, 1) and y_test.shape == (102,)\n",
    "except: \n",
    "   print(\"The result seems to be different. Try again with correct parameters.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8WCqPb5OSFw",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-87e49123e78d6a97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "17960fe6-d59d-4b7f-ab06-4c8da89db8a6"
   },
   "outputs": [],
   "source": [
    "#print the size of train and test dataset\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oFUhfDP9OSFw",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba1125ffb2594335",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this the degree of polynomial feature\n",
    "poly_degree = 2\n",
    "\n",
    "# build the polynomial feature space\n",
    "poly = PolynomialFeatures(degree=poly_degree, include_bias=False)\n",
    "x_train_poly = poly.fit_transform(x_train)\n",
    "\n",
    "# initial a linear regression model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# fit a linear regression to polynomial features.\n",
    "# tips: now you want to fit the model with the polynomical features you get from the previous step\n",
    "lin_reg.fit(x_train_poly, y_train)\n",
    "y_train_poly_pred = lin_reg.predict(x_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nSEq3dAeOSFw",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a20bde924d557ee9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "7434ef0b-da8a-4dc5-edb2-47d2e218e3fd"
   },
   "outputs": [],
   "source": [
    "# plot the results\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(x_train, y_train, marker='x')\n",
    "# sort the values of x before line plot\n",
    "sort_axis = operator.itemgetter(0)\n",
    "sorted_zip = sorted(zip(x_train,y_train_poly_pred), key=sort_axis)\n",
    "x_plot, y_poly_pred = zip(*sorted_zip)\n",
    "# plot the fitted line\n",
    "plt.plot(x_plot, y_poly_pred, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Bz_7nUpOSFw",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9791aed4c9851477",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q2.2:  print the result of residulas (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMhOvjrhOSFw",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9c0801fb4e12ac2a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# model evaluation for testing set\n",
    "# tips: now do the same polynomial transformation for validation set and calculat the MSE\n",
    "x_test_poly = poly.fit_transform(x_test)\n",
    "y_test_predict = lin_reg.predict(x_test_poly)\n",
    "mse = mean_squared_error(y_test, y_test_predict)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqfT63CLOSFx",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8623e93dd9006849",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "6017d2da-012e-4e29-ad40-d7eb3020ca96"
   },
   "outputs": [],
   "source": [
    "print(\"The model performance for validatiaon set\")\n",
    "print(\"--------------------------------------\")\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d01a6de436464940",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "try: \n",
    "   assert  20 <= mse <= 29\n",
    "except: \n",
    "   print(\"The result seems to be different. Try again with correct parameters.\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ut51N2xjOSFx",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7e984a9770a2b748",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Well Done! Now you know how to train a linear regression model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGOKyVb-OSFx",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-64668295dc90b880",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Addition task No.3:: How about a exponential feature space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2buGJscXOSFx",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9718becb8959c13b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "26eb0a51-c6b1-464f-87fc-97bf19f63d98"
   },
   "outputs": [],
   "source": [
    "# split the boston hoursing dataset into training and testing \n",
    "\n",
    "ratio = 0.2 # split ratio\n",
    "\n",
    "X = boston_data['LSTAT']\n",
    "\n",
    "Y = boston_data['MEDV']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "\n",
    "# print the size of train and test dataset\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_xHmBCxOSFx",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c872d205740f8698",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def func_exp(x, a, b, c):\n",
    "        #c = 0\n",
    "        return a * np.exp(b * x) + c\n",
    "\n",
    "def exponential_regression(x_data, y_data):\n",
    "    popt, pcov = curve_fit(func_exp, x_data, y_data, p0 = (-1, 0.01, 0))\n",
    "    print(popt)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    puntos = plt.plot(x_data, y_data, 'x', label = \"data\")\n",
    "    # tips: create exponential feature sapce using the aforedefined two functions: def func_exp and def exponential_regression\n",
    "    y_exp_pred = func_exp(x_data, *popt)\n",
    "    # sort the values of x before line plot\n",
    "    sort_axis = operator.itemgetter(0)\n",
    "    sorted_zip = sorted(zip(x_data,y_exp_pred), key=sort_axis)\n",
    "    x_data, y_exp_pred = zip(*sorted_zip)\n",
    "    curva_regresion = plt.plot(x_data, y_exp_pred , color='red')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Idvu8cW-OSFy",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ad4d1c8a5b3e2fbf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q3.1: apply the regression function to the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecb4rqpeOSFy",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4ad51d1bbe68ee06",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "cb220ec9-4f85-42fe-8196-7cd16f205bd7"
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "# tips: then fit a exponential regression model\n",
    "exponential_regression(x_train, y_train)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-60c060bf8c5bda69",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "try: \n",
    "   assert x_train.shape == y_train.shape == (404,) and x_test.shape == y_test.shape == (102,)\n",
    "except: \n",
    "   print(\"Incorrect usage of exponential_regression function\")\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a0473feac033ae0a72c844b4bc1e2ff3d183c066f94a97d6d9e653f25a975803"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
